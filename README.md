#### Model-based learning (ice-cream): 
The goal is to model an agent's behavior so that it parks a car as close to the ice-cream shop as possible in order to deliver ice cream to the shop as quickly as possible. We have modeled this as a Markov Decision Process and solved it using dynamic programming. We have employed value iteration and policy iteration using Python-based simulation to get the optimal policy for this problem set up. 
#### Model-free learning (robot-world): 
The goal is to teach an agent to push a bomb into a river as quickly as possible. In order to accomplish this we have employed model-free Q-learning and epsilon-greedy online Monte Carlo with constant alpha as we do not have a model of the environment. We have used Python-based simulation to get the optimal policy for the given example problem set up. After that, we have compared the two solution methods for different grid dimensions, reward structures and alpha and epsilon values, in terms of actual learning time, convergence and accuracy. We have also shown the path that our agent took in the example setup until the end of one random episode. 

